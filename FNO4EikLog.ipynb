{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"2,4\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utilities3 import *\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "from tqdm import trange\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from matplotlib import cm\n",
    "\n",
    "import time\n",
    "\n",
    "from timeit import default_timer\n",
    "\n",
    "from Adam import Adam\n",
    "\n",
    "\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul2d(self, input, weights):\n",
    "        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
    "        return torch.einsum(\"bixy,ioxy->boxy\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft2(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels,  x.size(-2), x.size(-1)//2 + 1, dtype=torch.cfloat, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfft2(out_ft, s=(x.size(-2), x.size(-1)))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNO2d(nn.Module):\n",
    "    def __init__(self, modes1, modes2,  width):\n",
    "        super(FNO2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the coefficient function and locations (a(x, y), x, y)\n",
    "        input shape: (batchsize, x=s, y=s, c=3)\n",
    "        output: the solution \n",
    "        output shape: (batchsize, x=s, y=s, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.width = width\n",
    "        self.padding = 9 # pad the domain if input is non-periodic\n",
    "        self.fc0 = nn.Linear(3, self.width) # input channel is 3: (a(x, y), x, y)\n",
    "\n",
    "        self.conv0 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv1 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv2 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv3 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.w0 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv2d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv2d(self.width, self.width, 1)\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        grid = self.get_grid(x.shape, x.device)\n",
    "        x = torch.cat((x, grid), dim=-1)\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = F.pad(x, [0,self.padding, 0,self.padding])\n",
    "\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = x[..., :-self.padding, :-self.padding]\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def get_grid(self, shape, device):\n",
    "        batchsize, size_x, size_y = shape[0], shape[1], shape[2]\n",
    "        gridx = torch.tensor(np.linspace(0, 1, size_x), dtype=torch.float)\n",
    "        gridx = gridx.reshape(1, size_x, 1, 1).repeat([batchsize, 1, size_y, 1])\n",
    "        gridy = torch.tensor(np.linspace(0, 1, size_y), dtype=torch.float)\n",
    "        gridy = gridy.reshape(1, 1, size_y, 1).repeat([batchsize, size_x, 1, 1])\n",
    "        return torch.cat((gridx, gridy), dim=-1).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comfigs\n",
    "Resmin, Resmax = [-1000,-1000,0], [80,1000,1000]\n",
    "masktest = 80\n",
    "IhbFile = \"/home/zqzhong/Dataset/dataset_train_v1/\"\n",
    "ArrFile = \"/home/zqzhong/Dataset/dataset_train_v2/\"\n",
    "FigFile = \"/home/zqzhong/AI4Science/Pro/Eikonal/FNO4Eik/FigSave/\"\n",
    "###################################\n",
    "ntrain = 40\n",
    "ntest = 10\n",
    "nforecast = 10\n",
    "batch_size = 1\n",
    "###################################\n",
    "learning_rate = 0.001\n",
    "epochs = 5000\n",
    "step_size = 500\n",
    "gamma = 0.5\n",
    "modes = 20 #? how to judge\n",
    "width = 40 #? how to pick\n",
    "r = 5\n",
    "s = int(Resmax[-1]/r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3],[4,5,6]])\n",
    "b = np.array([[1,2,4],[4,5,7]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RDevelop(Ihb):\n",
    "    '''\n",
    "    To transform the inhibitor distribution into that of development rate\n",
    "    '''\n",
    "    n, Mth = 30, 0.5\n",
    "    Rmax, Rmin = 40, 0.003\n",
    "    a = (n+1)/(n-1)*(1-Mth)**n\n",
    "    return Rmin+Rmax*(((a+1)*np.power(1-Ihb,n))/(a+np.power(1-Ihb,n)))\n",
    "\n",
    "\n",
    "def timepic(save_time):\n",
    "    timethis = str(save_time.tm_mon).zfill(2) + str(save_time.tm_mday).zfill(2) + str(save_time.tm_hour).zfill(2) + str(save_time.tm_min).zfill(2) \n",
    "    return timethis\n",
    "    \n",
    "\n",
    "def namepic(k, save_str):\n",
    "    namethis = str(k+ntrain+ntest).zfill(4) + save_str \n",
    "    return namethis\n",
    "\n",
    "def plotmesh(to_be_plot, name, save_time):\n",
    "    fig = plt.figure(figsize=(24,12))\n",
    "    plt.rcParams['font.size'] = '25'\n",
    "    Resmin, Resmax = [0,-1000,-1000], [80,1000,1000]\n",
    "    Y = np.arange(0, Resmax[1], r)\n",
    "    Z = np.arange(0, Resmax[2], r)\n",
    "    Y, Z = np.meshgrid(Y, Z)\n",
    "\n",
    "    levels = np.linspace(to_be_plot.min(), to_be_plot.max(),20)\n",
    "    ax = fig.add_subplot(121)\n",
    "    cset = ax.contourf(Y, Z, to_be_plot, levels, cmap=cm.jet)    \n",
    "    ax.set_title(name, fontsize='40')\n",
    "    plt.xlim(0, 200); plt.ylim(0, 200)\n",
    "    plt.xticks([0,500,1000]); plt.yticks([0,500,1000])\n",
    "    position = fig.add_axes([0.55, 0.2, 0.02, 0.6])\n",
    "    cbar = plt.colorbar(cset, pad=0, fraction=0, cax=position)\n",
    "    cbar.set_ticks([to_be_plot.min(),0.75*to_be_plot.min(),0.5*to_be_plot.min(),0.25*to_be_plot.min(),0,0.25*to_be_plot.max(),0.5*to_be_plot.max(),0.75*to_be_plot.max(),to_be_plot.max()], FormatStrFormatter('%.1f') )\n",
    "    #plt.show()\n",
    "    if not os.path.exists(FigFile + timepic(save_time)):\n",
    "        os.makedirs(FigFile + timepic(save_time))\n",
    "    plt.savefig(FigFile + timepic(save_time) + \"/\" +name)\n",
    "    \n",
    "def do_trans(nary):\n",
    "    ap = np.log(nary+1)\n",
    "    app = np.log(ap+1)\n",
    "    return app\n",
    "\n",
    "def de_trans(nary):\n",
    "    bpp = np.exp(nary)-1\n",
    "    bp = np.exp(bpp)-1\n",
    "    return bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starttime: 1669348915.750275\n",
      "IhbData.shape:  (80000, 1000)\n",
      "IhbData.shape:  (80, 1000, 1000)\n",
      "Runtime:  0.1639115810394287\n",
      "ArrData.shape:  (1000, 1000, 80)\n",
      "Runtime:  1.3407540321350098\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print(\"Starttime:\",t1)\n",
    "IhbData = np.load(IhbFile+str(2).zfill(4)+\"Inhibitor.npy\")\n",
    "print(\"IhbData.shape: \", IhbData.shape)\n",
    "IhbData = IhbData.reshape(Resmax)\n",
    "print(\"IhbData.shape: \", IhbData.shape)\n",
    "t2 = time.time()\n",
    "print(\"Runtime: \",t2-t1)\n",
    "ArrData = np.load(ArrFile+str(2).zfill(4)+\"Arrival.npy\")\n",
    "ArrData = do_trans(ArrData)\n",
    "print(\"ArrData.shape: \", ArrData.shape)\n",
    "t3 = time.time()\n",
    "print(\"Runtime: \",t3-t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plotmesh(IhbData[0,::r,::r].transpose())\n",
    "#plotmesh(ArrData[::r,::r,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Runtime:  0.48572778701782227\n",
      "Train set 0000 already loaded.\n",
      "1\n",
      "Runtime:  0.844398021697998\n",
      "Train set 0001 already loaded.\n",
      "2\n",
      "Runtime:  1.163517951965332\n",
      "Train set 0002 already loaded.\n",
      "3\n",
      "Runtime:  1.7508583068847656\n",
      "Train set 0003 already loaded.\n",
      "4\n",
      "Runtime:  2.095083713531494\n",
      "Train set 0004 already loaded.\n",
      "5\n",
      "Runtime:  2.432396173477173\n",
      "Train set 0005 already loaded.\n",
      "6\n",
      "Runtime:  2.7945609092712402\n",
      "Train set 0006 already loaded.\n",
      "7\n",
      "Runtime:  3.133946418762207\n",
      "Train set 0007 already loaded.\n",
      "8\n",
      "Runtime:  3.4947237968444824\n",
      "Train set 0008 already loaded.\n",
      "9\n",
      "Runtime:  3.8607683181762695\n",
      "Train set 0009 already loaded.\n",
      "10\n",
      "Runtime:  4.2169272899627686\n",
      "Train set 0010 already loaded.\n",
      "11\n",
      "Runtime:  4.54406213760376\n",
      "Train set 0011 already loaded.\n",
      "12\n",
      "Runtime:  4.889143705368042\n",
      "Train set 0012 already loaded.\n",
      "13\n",
      "Runtime:  5.230181455612183\n",
      "Train set 0013 already loaded.\n",
      "14\n",
      "Runtime:  5.574290037155151\n",
      "Train set 0014 already loaded.\n",
      "15\n",
      "Runtime:  5.925131797790527\n",
      "Train set 0015 already loaded.\n",
      "16\n",
      "Runtime:  6.2730231285095215\n",
      "Train set 0016 already loaded.\n",
      "17\n",
      "Runtime:  6.632984161376953\n",
      "Train set 0017 already loaded.\n",
      "18\n",
      "Runtime:  6.969001531600952\n",
      "Train set 0018 already loaded.\n",
      "19\n",
      "Runtime:  7.297163724899292\n",
      "Train set 0019 already loaded.\n",
      "20\n",
      "Runtime:  7.621328830718994\n",
      "Train set 0020 already loaded.\n",
      "21\n",
      "Runtime:  7.942593812942505\n",
      "Train set 0021 already loaded.\n",
      "22\n",
      "Runtime:  8.298143863677979\n",
      "Train set 0022 already loaded.\n",
      "23\n",
      "Runtime:  8.644785165786743\n",
      "Train set 0023 already loaded.\n",
      "24\n",
      "Runtime:  9.003392934799194\n",
      "Train set 0024 already loaded.\n",
      "25\n",
      "Runtime:  9.327601194381714\n",
      "Train set 0025 already loaded.\n",
      "26\n",
      "Runtime:  9.662762641906738\n",
      "Train set 0026 already loaded.\n",
      "27\n",
      "Runtime:  9.995256900787354\n",
      "Train set 0027 already loaded.\n",
      "28\n",
      "Runtime:  10.334809303283691\n",
      "Train set 0028 already loaded.\n",
      "29\n",
      "Runtime:  10.664013385772705\n",
      "Train set 0029 already loaded.\n",
      "30\n",
      "Runtime:  10.991667032241821\n",
      "Train set 0030 already loaded.\n",
      "31\n",
      "Runtime:  11.30963945388794\n",
      "Train set 0031 already loaded.\n",
      "32\n",
      "Runtime:  11.652905225753784\n",
      "Train set 0032 already loaded.\n",
      "33\n",
      "Runtime:  12.002272605895996\n",
      "Train set 0033 already loaded.\n",
      "34\n",
      "Runtime:  12.331543445587158\n",
      "Train set 0034 already loaded.\n",
      "35\n",
      "Runtime:  12.658546447753906\n",
      "Train set 0035 already loaded.\n",
      "36\n",
      "Runtime:  12.977770566940308\n",
      "Train set 0036 already loaded.\n",
      "37\n",
      "Runtime:  13.296561241149902\n",
      "Train set 0037 already loaded.\n",
      "38\n",
      "Runtime:  13.644293308258057\n",
      "Train set 0038 already loaded.\n",
      "39\n",
      "Runtime:  13.971867561340332\n",
      "Train set 0039 already loaded.\n",
      "x_train_list.shape:  (40, 200, 200, 1)\n",
      "y_train_list.shape:  (40, 200, 200, 1)\n",
      "Runtime:  14.299311399459839\n",
      "Test  set 0040 already loaded.\n",
      "Runtime:  14.61314058303833\n",
      "Test  set 0041 already loaded.\n",
      "Runtime:  14.9457368850708\n",
      "Test  set 0042 already loaded.\n",
      "Runtime:  15.27199387550354\n",
      "Test  set 0043 already loaded.\n",
      "Runtime:  15.614283800125122\n",
      "Test  set 0044 already loaded.\n",
      "Runtime:  15.93650221824646\n",
      "Test  set 0045 already loaded.\n",
      "Runtime:  16.260895252227783\n",
      "Test  set 0046 already loaded.\n",
      "Runtime:  16.576722860336304\n",
      "Test  set 0047 already loaded.\n",
      "Runtime:  16.931623220443726\n",
      "Test  set 0048 already loaded.\n",
      "Runtime:  17.257269382476807\n",
      "Test  set 0049 already loaded.\n",
      "x_test_list.shape:  (10, 200, 200, 1)\n",
      "y_test_list.shape:  (10, 200, 200, 1)\n",
      "Runtime:  17.566746711730957\n",
      "Forecastset 0050 already loaded.\n",
      "Runtime:  17.882798433303833\n",
      "Forecastset 0051 already loaded.\n",
      "Runtime:  18.22202730178833\n",
      "Forecastset 0052 already loaded.\n",
      "Runtime:  18.54058265686035\n",
      "Forecastset 0053 already loaded.\n",
      "Runtime:  18.868135452270508\n",
      "Forecastset 0054 already loaded.\n",
      "Runtime:  19.200219869613647\n",
      "Forecastset 0055 already loaded.\n",
      "Runtime:  19.540762901306152\n",
      "Forecastset 0056 already loaded.\n",
      "Runtime:  19.881682872772217\n",
      "Forecastset 0057 already loaded.\n",
      "Runtime:  20.24299955368042\n",
      "Forecastset 0058 already loaded.\n",
      "Runtime:  20.614335775375366\n",
      "Forecastset 0059 already loaded.\n"
     ]
    }
   ],
   "source": [
    "#Load Data\n",
    "x_train_list = np.empty([ntrain, s, s])\n",
    "y_train_list = np.empty([ntrain, s, s])\n",
    "x_test_list = np.empty([ntest, s, s])\n",
    "y_test_list = np.empty([ntest, s, s])\n",
    "x_fc_list = np.empty([nforecast, s, s])\n",
    "y_fc_list = np.empty([nforecast, s, s])\n",
    "\n",
    "t3 = time.time()\n",
    "for k in range(ntrain):\n",
    "    \n",
    "    print(k)\n",
    "    IhbData = np.load(IhbFile+str(k).zfill(4)+\"Inhibitor.npy\").reshape(Resmax)\n",
    "    ArrData = np.load(ArrFile+str(k).zfill(4)+\"Arrival.npy\")\n",
    "    \n",
    "    x_train_pre = IhbData[0,::r,::r].transpose()\n",
    "    #print(\"IhbData \"+str(k).zfill(4)+\" already loaded.\")\n",
    "    x_train = RDevelop(x_train_pre)\n",
    "    #print(\"IhbData \"+str(k).zfill(4)+\" already transfered.\")\n",
    "    y_train = do_trans(ArrData[::r,::r,0])\n",
    "    #print(\"ArrData \"+str(k).zfill(4)+\" already loaded.\")\n",
    "    \n",
    "    # x_normalizer = UnitGaussianNormalizer(x_train)\n",
    "    # x_train = x_normalizer.encode(x_train)\n",
    "    x_train = x_train.reshape(1,s,s)\n",
    "    \n",
    "    # y_normalizer = UnitGaussianNormalizer(y_train)\n",
    "    # y_train = y_normalizer.encode(y_train)\n",
    "    y_train = y_train.reshape(1,s,s)\n",
    "    \n",
    "    x_train_list[k] = x_train\n",
    "    y_train_list[k] = y_train\n",
    "    \n",
    "    t4 = time.time()\n",
    "    print(\"Runtime: \",t4-t3)\n",
    "    print(\"Train set \"+str(k).zfill(4)+\" already loaded.\")\n",
    "\n",
    "print(\"x_train_list.shape: \", x_train_list.shape)\n",
    "print(\"y_train_list.shape: \", y_train_list.shape) \n",
    "for k in range(ntrain, ntrain + ntest):\n",
    "    \n",
    "    IhbData = np.load(IhbFile+str(k).zfill(4)+\"Inhibitor.npy\").reshape(Resmax)\n",
    "    ArrData = np.load(ArrFile+str(k).zfill(4)+\"Arrival.npy\")\n",
    "    \n",
    "    \n",
    "    x_test_pre = IhbData[0,::r,::r].transpose()\n",
    "    x_test = RDevelop(x_test_pre)\n",
    "    y_test = do_trans(ArrData[::r,::r,0])\n",
    "    \n",
    "    # x_normalizer = UnitGaussianNormalizer(x_test)\n",
    "    # x_test = x_normalizer.encode(x_test)\n",
    "    x_test = x_test.reshape(1,s,s)\n",
    "    \n",
    "    # y_normalizer = UnitGaussianNormalizer(y_test)\n",
    "    # y_test = y_normalizer.encode(y_test)\n",
    "    y_test = y_test.reshape(1,s,s)\n",
    "    \n",
    "    x_test_list[k-ntrain] = x_test\n",
    "    y_test_list[k-ntrain] = y_test\n",
    "    t4 = time.time()\n",
    "    print(\"Runtime: \",t4-t3)\n",
    "    print(\"Test  set \"+str(k).zfill(4)+\" already loaded.\")\n",
    "\n",
    "print(\"x_test_list.shape: \", x_test_list.shape) \n",
    "print(\"y_test_list.shape: \", y_test_list.shape)\n",
    "for k in range(ntrain + ntest, ntrain + ntest + nforecast):\n",
    "    \n",
    "    IhbData = np.load(IhbFile+str(k).zfill(4)+\"Inhibitor.npy\").reshape(Resmax)\n",
    "    ArrData = np.load(ArrFile+str(k).zfill(4)+\"Arrival.npy\")\n",
    "    \n",
    "    #print(\"IhbData.shape: \", IhbData.shape)\n",
    "    #print(\"ArrData.shape: \", ArrData.shape)\n",
    "    \n",
    "    x_fc_pre = IhbData[0,::r,::r].transpose()\n",
    "    x_fc = RDevelop(x_fc_pre)\n",
    "    y_fc = do_trans(ArrData[::r,::r,0])\n",
    "    \n",
    "    # x_normalizer = UnitGaussianNormalizer(x_test)\n",
    "    # x_fc = x_normalizer.encode(x_test)\n",
    "    x_fc = x_fc.reshape(1,s,s)\n",
    "    \n",
    "    # y_normalizer = UnitGaussianNormalizer(y_test)\n",
    "    # y_test = y_normalizer.encode(y_test)\n",
    "    y_fc = y_fc.reshape(1,s,s)\n",
    "    \n",
    "    x_fc_list[k - ntrain - ntest,:,:] = x_fc\n",
    "    y_fc_list[k - ntrain - ntest,:,:] = y_fc\n",
    "    #print(\"x_fc_list.shape: \", x_fc_list.shape)\n",
    "    #print(\"y_fc_list.shape: \", y_fc_list.shape)\n",
    "    t4 = time.time()\n",
    "    print(\"Runtime: \",t4-t3)\n",
    "    print(\"Forecastset \"+str(k).zfill(4)+\" already loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_list = torch.tensor(x_train_list,dtype=torch.float32)\n",
    "y_train_list = torch.tensor(y_train_list,dtype=torch.float32)\n",
    "\n",
    "x_test_list = torch.tensor(x_test_list,dtype=torch.float32)\n",
    "y_test_list = torch.tensor(y_test_list,dtype=torch.float32)\n",
    "\n",
    "x_fc_list = torch.tensor(x_fc_list,dtype=torch.float32)\n",
    "y_fc_list = torch.tensor(y_fc_list,dtype=torch.float32)\n",
    "\n",
    "x_train_list = x_train_list.reshape(ntrain, s, s, 1)\n",
    "x_test_list = x_test_list.reshape(ntest, s, s, 1)\n",
    "x_fc_list = x_fc_list.reshape(nforecast, s, s, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train_list, y_train_list), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test_list, y_test_list), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10252097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████     | 2238/5000 [27:09<32:21,  1.42it/s, train_loss=0.00125, test_loss=0.00853]"
     ]
    }
   ],
   "source": [
    "# training and evaluation\n",
    "model = FNO2d(modes, modes, width).cuda()\n",
    "print(count_params(model))\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "myloss = LpLoss(size_average=False)\n",
    "loss_train_log = []\n",
    "loss_test_log = []\n",
    "pbar = trange(epochs)\n",
    "\n",
    "y_train_list.cuda()\n",
    "for ep in pbar:\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_l2 = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x).reshape(batch_size, s, s)\n",
    "        \n",
    "        # print(\"x.shape:\",x.shape,\" y.shape:\",y.shape,\" out.shape:\",out.shape)\n",
    "\n",
    "        loss = myloss(out.view(batch_size,-1), y.view(batch_size,-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_l2 += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    test_l2 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "\n",
    "            out = model(x).reshape(batch_size, s, s)\n",
    "            \n",
    "            test_l2 += myloss(out.view(batch_size,-1), y.view(batch_size,-1)).item()\n",
    "\n",
    "    train_l2/= ntrain\n",
    "    test_l2/= ntest\n",
    "\n",
    "    t2 = default_timer()\n",
    "    loss_train_log.append(train_l2)\n",
    "    loss_test_log.append(test_l2)\n",
    "    if ep % 5 == 0:\n",
    "        pbar.set_postfix({'train_loss': train_l2, \n",
    "                    'test_loss' : test_l2})\n",
    "    #print(ep, t2-t1, train_l2, test_l2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SavePath = \"/home/zqzhong/AI4Science/Pro/Eikonal/FNO4Eik/trained_model/\"\n",
    "save_time = time.ctime()\n",
    "save_time = time.strptime(save_time)\n",
    "torch.save(model, SavePath + \"Trained_Model_\" + str(save_time.tm_mon).zfill(2) + str(save_time.tm_mday).zfill(2) + str(save_time.tm_hour).zfill(2) + str(save_time.tm_min).zfill(2)+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,15))\n",
    "plt.plot(loss_train_log, lw=2, label='train')\n",
    "plt.plot(loss_test_log, lw=2, label='test')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "if not os.path.exists(FigFile + timepic(save_time)):\n",
    "    os.makedirs(FigFile + timepic(save_time))\n",
    "plt.savefig(FigFile + timepic(save_time) + \"/\" + \"loss_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x_fc_list.shape)\n",
    "\n",
    "for k in range (nforecast):\n",
    "    plot_test_x = x_fc_list[k:k+1,:,:,:].cuda()\n",
    "    #print(\"plot_test_x.shape: \",plot_test_x.shape)\n",
    "    plot_test_y_log = model(plot_test_x).reshape(1,s,s)\n",
    "    #print(\"plot_test_y_log.shape: \",plot_test_y_log.shape)\n",
    "    plot_test_y_log = plot_test_y_log.cpu().detach().numpy()[0,:,:]\n",
    "    #plot_test_y = plot_test_y.reshape((200,200))\n",
    "    plot_test_y = de_trans(plot_test_y_log)\n",
    "    plot_test_y_ref_log = y_fc_list.cpu().detach().numpy()[k,:,:]\n",
    "    print(\"plot_test_y_ref_log.shape: \",plot_test_y_ref_log.shape)\n",
    "    plot_test_y_ref = de_trans(plot_test_y_ref_log)\n",
    "    plot_test_err = plot_test_y - plot_test_y_ref\n",
    "    print(\"The \",k+ntrain+ntest,\"st Forecast result\")\n",
    "    #save_time = time.strptime(now)\n",
    "    \n",
    "    print(\"True_Arrival_log\")\n",
    "    name1 = namepic(k, \"True_Arrival_log\")\n",
    "    plotmesh(plot_test_y_ref_log, name1, save_time)\n",
    "    \n",
    "    print(\"True Arrival\")\n",
    "    name2 = namepic(k, \"True_Arrival\")\n",
    "    plotmesh(plot_test_y_ref, name2, save_time)\n",
    "    \n",
    "    print(\"Predict Arrival log\")\n",
    "    name3 = namepic(k, \"Predict_Arrival_log\")\n",
    "    plotmesh(plot_test_y_log, name3, save_time)\n",
    "    \n",
    "    print(\"Predict Arrival\")\n",
    "    name4 = namepic(k, \"Predict_Arrival\")\n",
    "    plotmesh(plot_test_y, name4, save_time)\n",
    "    \n",
    "    print(\"Error\")\n",
    "    name5 = namepic(k, \"Error\")\n",
    "    plotmesh(plot_test_err, name5, save_time)\n",
    "    \n",
    "    print(\"plot_test_y_ref.max(): \",abs(plot_test_y_ref).max())\n",
    "    print(\"plot_test_err.max(): \",abs(plot_test_err).max())\n",
    "    print(\"===================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1fcb0b3d4d434f53f389ecf9b58271976f40054f16aa104601344aac6b320b3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
